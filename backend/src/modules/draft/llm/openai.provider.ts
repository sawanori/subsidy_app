import { Injectable, Logger } from '@nestjs/common';
import OpenAI from 'openai';
import {
  LLMProvider,
  LLMOptions,
  LLMResponse,
} from './llm.provider.interface';

@Injectable()
export class OpenAIProvider implements LLMProvider {
  private readonly logger = new Logger(OpenAIProvider.name);
  private client: OpenAI;
  private readonly defaultModel = 'gpt-4o-mini';

  constructor() {
    const apiKey = process.env.OPENAI_API_KEY;

    if (!apiKey || apiKey === '') {
      this.logger.warn('âš ï¸  OPENAI_API_KEY is not set. OpenAI calls will fail.');
      this.logger.warn('ğŸ’¡ Consider using MockOpenAIProvider for development.');
    }

    this.client = new OpenAI({
      apiKey: apiKey || 'sk-mock-key-for-development',
    });
  }

  /**
   * LLMProviderå®Ÿè£…: ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
   */
  async generate(prompt: string, options?: LLMOptions): Promise<LLMResponse> {
    const startTime = Date.now();
    const model = options?.model || this.defaultModel;

    try {
      const response = await this.client.chat.completions.create({
        model,
        messages: [{ role: 'user', content: prompt }],
        temperature: options?.temperature ?? 0.7,
        max_tokens: options?.maxTokens ?? 4000,
        top_p: options?.topP,
        frequency_penalty: options?.frequencyPenalty,
        presence_penalty: options?.presencePenalty,
      });

      const duration = Date.now() - startTime;
      const tokensUsed = {
        prompt: response.usage?.prompt_tokens || 0,
        completion: response.usage?.completion_tokens || 0,
        total: response.usage?.total_tokens || 0,
      };

      const estimatedCost = this.calculateCost(tokensUsed.total, model);

      return {
        text: response.choices[0].message.content || '',
        model,
        tokensUsed,
        duration,
        estimatedCost,
        metadata: {
          finishReason: response.choices[0].finish_reason,
          id: response.id,
        },
      };
    } catch (error) {
      this.logger.error(`OpenAI generation failed: ${error.message}`);
      throw new Error(`OpenAI generation failed: ${error.message}`);
    }
  }

  /**
   * LLMProviderå®Ÿè£…: ã‚³ã‚¹ãƒˆè¨ˆç®—
   */
  calculateCost(tokens: number, model: string): number {
    const pricePerMillion: { [key: string]: number } = {
      'gpt-4o': 2.5, // Input $2.50/1M tokens
      'gpt-4o-mini': 0.15, // Input $0.15/1M tokens
      'gpt-4-turbo': 10.0, // Input $10.00/1M tokens
      'gpt-3.5-turbo': 0.5, // Input $0.50/1M tokens
    };

    const price = pricePerMillion[model] || pricePerMillion['gpt-4o-mini'];
    const usdCost = (tokens / 1_000_000) * price;
    const jpyRate = 150; // USD to JPY
    return parseFloat((usdCost * jpyRate).toFixed(2));
  }

  /**
   * LLMProviderå®Ÿè£…: ãƒ—ãƒ­ãƒã‚¤ãƒ€åå–å¾—
   */
  getProviderName(): string {
    return 'openai';
  }

  /**
   * LLMProviderå®Ÿè£…: åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
   */
  getAvailableModels(): string[] {
    return ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-3.5-turbo'];
  }

  /**
   * LLMProviderå®Ÿè£…: ãƒˆãƒ¼ã‚¯ãƒ³æ•°æ¨å®š
   *
   * ç°¡æ˜“çš„ãªæ¨å®šï¼ˆè‹±èª: 4æ–‡å­—/tokenã€æ—¥æœ¬èª: 1.5æ–‡å­—/tokenï¼‰
   */
  estimateTokens(text: string): number {
    const japaneseChars = (text.match(/[\u3000-\u9FFF]/g) || []).length;
    const otherChars = text.length - japaneseChars;

    const japaneseTokens = japaneseChars / 1.5;
    const otherTokens = otherChars / 4;

    return Math.ceil(japaneseTokens + otherTokens);
  }

  /**
   * ãƒ¬ã‚¬ã‚·ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰: å¸‚å ´åˆ†æèª¬æ˜æ–‡ç”Ÿæˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
   */
  async generateExplanation(data: {
    title: string;
    dataPoints: any[];
  }): Promise<string> {
    const prompt = `
ã‚ãªãŸã¯è£œåŠ©é‡‘ç”³è«‹æ›¸é¡ã®ä½œæˆã‚’æ”¯æ´ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€å¸‚å ´åˆ†æã®èª¬æ˜æ–‡ã‚’200-300å­—ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‡ãƒ¼ã‚¿ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: ${data.title}
ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: ${JSON.stringify(data.dataPoints, null, 2)}

ã€è¦ä»¶ã€‘
- æ•°å€¤ã¯ä¸Šè¨˜å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ­£ç¢ºã«å¼•ç”¨ã™ã‚‹ã“ã¨
- å°‚é–€çš„ã‹ã¤å®¢è¦³çš„ãªè¡¨ç¾ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨
- ã€Œç¢ºå®Ÿã«ã€ã€Œå¿…ãšã€ã€Œçµ¶å¯¾ã«ã€ãªã©ã®æ–­å®šè¡¨ç¾ã¯ä½¿ç”¨ã—ãªã„ã“ã¨
- ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„æˆé•·ç‡ãŒã‚ã‚Œã°è¨€åŠã™ã‚‹ã“ã¨
`;

    const response = await this.generate(prompt, {
      model: 'gpt-4o-mini',
      temperature: 0.7,
      maxTokens: 500,
    });

    return response.text;
  }
}